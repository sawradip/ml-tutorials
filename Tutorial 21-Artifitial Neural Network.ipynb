{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Tutorial 21-Artifitial Neural Network.ipynb","provenance":[{"file_id":"1HslgbAWrN2HPOq9yOtqrGSwwqEIZhGsK","timestamp":1593281500673}],"collapsed_sections":[],"authorship_tag":"ABX9TyPXnD17HiroFKcnlxieTFzS"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"1yULruM-zKgz","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593281911427,"user_tz":-360,"elapsed":871,"user":{"displayName":"Sawradip Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjiknncyResq9DxB1krpJnhEFgTIz65ifrUq64R2hs=s64","userId":"07399611378604694216"}}},"source":["# Importing the libraries\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"qU5Yxwbe0Yck","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593282935387,"user_tz":-360,"elapsed":1098,"user":{"displayName":"Sawradip Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjiknncyResq9DxB1krpJnhEFgTIz65ifrUq64R2hs=s64","userId":"07399611378604694216"}}},"source":["# Importing the dataset\n","dataset = pd.read_csv('Churn_Modelling.csv')\n","\n","X = dataset.iloc[:,3:13].values\n","y = dataset.iloc[:,-1].values"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vq5DgUiLEqLv","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593282937177,"user_tz":-360,"elapsed":1088,"user":{"displayName":"Sawradip Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjiknncyResq9DxB1krpJnhEFgTIz65ifrUq64R2hs=s64","userId":"07399611378604694216"}}},"source":["#Encoding categorical data\n","\n","from sklearn.preprocessing import LabelEncoder , OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","\n","labelencoder_X_1 = LabelEncoder()                                                 #the categorical data (country & label here) will be  \n","X[:,1] = labelencoder_x_1.fit_transform(X[:,1])                                   #transformed into labels(0,1,2.....)\n","\n","labelencoder_X_2 = LabelEncoder()\n","X[:,2] = labelencoder_X_2.fit_transform(X[:,2] )\n","\n","columntransformer = ColumnTransformer([('Countries', OneHotEncoder() , [1])] , remainder = \"passthrough\")            #but if some countries are labeled with higher values\n","X = columntransformer.fit_transform(X)                                                                          #that can be misleading, so we transform them to one-hot vectors.\n","X = X[: , 1:]\n","\n"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZDvr2y-vDhzE","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593283103744,"user_tz":-360,"elapsed":1588,"user":{"displayName":"Sawradip Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjiknncyResq9DxB1krpJnhEFgTIz65ifrUq64R2hs=s64","userId":"07399611378604694216"}}},"source":["#Splitting the dataset into Training set and Test set\n","\n","from sklearn.model_selection import train_test_split\n","\n","X_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 0.2 , random_state = 0)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"7s0om0gq01_J","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593283341991,"user_tz":-360,"elapsed":1396,"user":{"displayName":"Sawradip Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjiknncyResq9DxB1krpJnhEFgTIz65ifrUq64R2hs=s64","userId":"07399611378604694216"}}},"source":["#Feature Scaling\n","\n","from sklearn.preprocessing import StandardScaler\n","\n","sc_X = StandardScaler()\n","\n","X_train = sc_X.fit_transform(X_train)\n","X_test = sc_X.transform(X_test)"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"KpHgKEcN033a","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593283669080,"user_tz":-360,"elapsed":1222,"user":{"displayName":"Sawradip Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjiknncyResq9DxB1krpJnhEFgTIz65ifrUq64R2hs=s64","userId":"07399611378604694216"}}},"source":["#Importing the Keras libraries and packages\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wu-5puc-4lCp","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593284675726,"user_tz":-360,"elapsed":1288,"user":{"displayName":"Sawradip Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjiknncyResq9DxB1krpJnhEFgTIz65ifrUq64R2hs=s64","userId":"07399611378604694216"}}},"source":["#Initializing the ANN\n","classifier = Sequential()\n","\n","#Adding the Input layer and the first hidden layer\n","classifier.add(Dense(6 , activation = 'relu' ))\n","\n","#Adding the second hidden layer \n","classifier.add(Dense(6 , activation = 'relu' ))\n","\n","#Adding the output layer\n","classifier.add(Dense(1 , activation = 'sigmoid' ))"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"B4zXxhytI6O9","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593284966877,"user_tz":-360,"elapsed":1416,"user":{"displayName":"Sawradip Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjiknncyResq9DxB1krpJnhEFgTIz65ifrUq64R2hs=s64","userId":"07399611378604694216"}}},"source":["#Compiling the ANN\n","\n","classifier.compile(optimizer = 'adam' , loss='binary_crossentropy' , metrics = ['accuracy'])\n"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"s-0zqbOYLNmS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593285271390,"user_tz":-360,"elapsed":90128,"user":{"displayName":"Sawradip Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjiknncyResq9DxB1krpJnhEFgTIz65ifrUq64R2hs=s64","userId":"07399611378604694216"}},"outputId":"c7ddd4ef-9de9-409e-d8d5-96d08bbf22ba"},"source":["#Fitting the ANN to the training set\n","\n","classifier.fit(X_train , y_train , batch_size = 10 ,epochs = 100)"],"execution_count":28,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","8000/8000 [==============================] - 1s 145us/step - loss: 0.4827 - accuracy: 0.7830\n","Epoch 2/100\n","8000/8000 [==============================] - 1s 117us/step - loss: 0.4254 - accuracy: 0.8064\n","Epoch 3/100\n","8000/8000 [==============================] - 1s 108us/step - loss: 0.4155 - accuracy: 0.8126\n","Epoch 4/100\n","8000/8000 [==============================] - 1s 105us/step - loss: 0.4089 - accuracy: 0.8180\n","Epoch 5/100\n","8000/8000 [==============================] - 1s 102us/step - loss: 0.4037 - accuracy: 0.8181\n","Epoch 6/100\n","8000/8000 [==============================] - 1s 104us/step - loss: 0.3992 - accuracy: 0.8198\n","Epoch 7/100\n","8000/8000 [==============================] - 1s 117us/step - loss: 0.3948 - accuracy: 0.8231\n","Epoch 8/100\n","8000/8000 [==============================] - 1s 103us/step - loss: 0.3911 - accuracy: 0.8248\n","Epoch 9/100\n","8000/8000 [==============================] - 1s 120us/step - loss: 0.3879 - accuracy: 0.8261\n","Epoch 10/100\n","8000/8000 [==============================] - 1s 108us/step - loss: 0.3842 - accuracy: 0.8276\n","Epoch 11/100\n","8000/8000 [==============================] - 1s 103us/step - loss: 0.3809 - accuracy: 0.8273\n","Epoch 12/100\n","8000/8000 [==============================] - 1s 122us/step - loss: 0.3779 - accuracy: 0.8285\n","Epoch 13/100\n","8000/8000 [==============================] - 1s 122us/step - loss: 0.3744 - accuracy: 0.8286\n","Epoch 14/100\n","8000/8000 [==============================] - 1s 115us/step - loss: 0.3715 - accuracy: 0.8432\n","Epoch 15/100\n","8000/8000 [==============================] - 1s 104us/step - loss: 0.3681 - accuracy: 0.8485\n","Epoch 16/100\n","8000/8000 [==============================] - 1s 102us/step - loss: 0.3659 - accuracy: 0.8489\n","Epoch 17/100\n","8000/8000 [==============================] - 1s 102us/step - loss: 0.3632 - accuracy: 0.8499\n","Epoch 18/100\n","8000/8000 [==============================] - 1s 101us/step - loss: 0.3611 - accuracy: 0.8540\n","Epoch 19/100\n","8000/8000 [==============================] - 1s 106us/step - loss: 0.3594 - accuracy: 0.8530\n","Epoch 20/100\n","8000/8000 [==============================] - 1s 112us/step - loss: 0.3579 - accuracy: 0.8535\n","Epoch 21/100\n","8000/8000 [==============================] - 1s 103us/step - loss: 0.3574 - accuracy: 0.8558\n","Epoch 22/100\n","8000/8000 [==============================] - 1s 117us/step - loss: 0.3565 - accuracy: 0.8564\n","Epoch 23/100\n","8000/8000 [==============================] - 1s 105us/step - loss: 0.3561 - accuracy: 0.8561\n","Epoch 24/100\n","8000/8000 [==============================] - 1s 102us/step - loss: 0.3550 - accuracy: 0.8575\n","Epoch 25/100\n","8000/8000 [==============================] - 1s 110us/step - loss: 0.3545 - accuracy: 0.8568\n","Epoch 26/100\n","8000/8000 [==============================] - 1s 105us/step - loss: 0.3534 - accuracy: 0.8580\n","Epoch 27/100\n","8000/8000 [==============================] - 1s 105us/step - loss: 0.3527 - accuracy: 0.8581\n","Epoch 28/100\n","8000/8000 [==============================] - 1s 109us/step - loss: 0.3520 - accuracy: 0.8584\n","Epoch 29/100\n","8000/8000 [==============================] - 1s 112us/step - loss: 0.3519 - accuracy: 0.8555\n","Epoch 30/100\n","8000/8000 [==============================] - 1s 119us/step - loss: 0.3512 - accuracy: 0.8575\n","Epoch 31/100\n","8000/8000 [==============================] - 1s 118us/step - loss: 0.3512 - accuracy: 0.8595\n","Epoch 32/100\n","8000/8000 [==============================] - 1s 107us/step - loss: 0.3500 - accuracy: 0.8568\n","Epoch 33/100\n","8000/8000 [==============================] - 1s 117us/step - loss: 0.3508 - accuracy: 0.8595\n","Epoch 34/100\n","8000/8000 [==============================] - 1s 112us/step - loss: 0.3495 - accuracy: 0.8595\n","Epoch 35/100\n","8000/8000 [==============================] - 1s 109us/step - loss: 0.3497 - accuracy: 0.8604\n","Epoch 36/100\n","8000/8000 [==============================] - 1s 112us/step - loss: 0.3494 - accuracy: 0.8597\n","Epoch 37/100\n","8000/8000 [==============================] - 1s 118us/step - loss: 0.3494 - accuracy: 0.8584\n","Epoch 38/100\n","8000/8000 [==============================] - 1s 118us/step - loss: 0.3490 - accuracy: 0.8579\n","Epoch 39/100\n","8000/8000 [==============================] - 1s 114us/step - loss: 0.3478 - accuracy: 0.8596\n","Epoch 40/100\n","8000/8000 [==============================] - 1s 105us/step - loss: 0.3484 - accuracy: 0.8571\n","Epoch 41/100\n","8000/8000 [==============================] - 1s 105us/step - loss: 0.3482 - accuracy: 0.8601\n","Epoch 42/100\n","8000/8000 [==============================] - 1s 105us/step - loss: 0.3474 - accuracy: 0.8593\n","Epoch 43/100\n","8000/8000 [==============================] - 1s 109us/step - loss: 0.3476 - accuracy: 0.8589\n","Epoch 44/100\n","8000/8000 [==============================] - 1s 111us/step - loss: 0.3469 - accuracy: 0.8597\n","Epoch 45/100\n","8000/8000 [==============================] - 1s 104us/step - loss: 0.3462 - accuracy: 0.8601\n","Epoch 46/100\n","8000/8000 [==============================] - 1s 106us/step - loss: 0.3477 - accuracy: 0.8602\n","Epoch 47/100\n","8000/8000 [==============================] - 1s 105us/step - loss: 0.3460 - accuracy: 0.8630\n","Epoch 48/100\n","8000/8000 [==============================] - 1s 103us/step - loss: 0.3461 - accuracy: 0.8618\n","Epoch 49/100\n","8000/8000 [==============================] - 1s 110us/step - loss: 0.3456 - accuracy: 0.8606\n","Epoch 50/100\n","8000/8000 [==============================] - 1s 110us/step - loss: 0.3454 - accuracy: 0.8620\n","Epoch 51/100\n","8000/8000 [==============================] - 1s 118us/step - loss: 0.3456 - accuracy: 0.8627\n","Epoch 52/100\n","8000/8000 [==============================] - 1s 122us/step - loss: 0.3442 - accuracy: 0.8636\n","Epoch 53/100\n","8000/8000 [==============================] - 1s 116us/step - loss: 0.3452 - accuracy: 0.8610\n","Epoch 54/100\n","8000/8000 [==============================] - 1s 112us/step - loss: 0.3444 - accuracy: 0.8610\n","Epoch 55/100\n","8000/8000 [==============================] - 1s 117us/step - loss: 0.3440 - accuracy: 0.8602\n","Epoch 56/100\n","8000/8000 [==============================] - 1s 104us/step - loss: 0.3439 - accuracy: 0.8627\n","Epoch 57/100\n","8000/8000 [==============================] - 1s 106us/step - loss: 0.3427 - accuracy: 0.8619\n","Epoch 58/100\n","8000/8000 [==============================] - 1s 123us/step - loss: 0.3438 - accuracy: 0.8611\n","Epoch 59/100\n","8000/8000 [==============================] - 1s 122us/step - loss: 0.3432 - accuracy: 0.8615\n","Epoch 60/100\n","8000/8000 [==============================] - 1s 118us/step - loss: 0.3436 - accuracy: 0.8630\n","Epoch 61/100\n","8000/8000 [==============================] - 1s 107us/step - loss: 0.3431 - accuracy: 0.8615\n","Epoch 62/100\n","8000/8000 [==============================] - 1s 120us/step - loss: 0.3430 - accuracy: 0.8615\n","Epoch 63/100\n","8000/8000 [==============================] - 1s 122us/step - loss: 0.3428 - accuracy: 0.8625\n","Epoch 64/100\n","8000/8000 [==============================] - 1s 108us/step - loss: 0.3426 - accuracy: 0.8604\n","Epoch 65/100\n","8000/8000 [==============================] - 1s 107us/step - loss: 0.3430 - accuracy: 0.8620\n","Epoch 66/100\n","8000/8000 [==============================] - 1s 106us/step - loss: 0.3426 - accuracy: 0.8614\n","Epoch 67/100\n","8000/8000 [==============================] - 1s 106us/step - loss: 0.3422 - accuracy: 0.8615\n","Epoch 68/100\n","8000/8000 [==============================] - 1s 107us/step - loss: 0.3424 - accuracy: 0.8634\n","Epoch 69/100\n","8000/8000 [==============================] - 1s 121us/step - loss: 0.3420 - accuracy: 0.8622\n","Epoch 70/100\n","8000/8000 [==============================] - 1s 104us/step - loss: 0.3422 - accuracy: 0.8639\n","Epoch 71/100\n","8000/8000 [==============================] - 1s 104us/step - loss: 0.3421 - accuracy: 0.8612\n","Epoch 72/100\n","8000/8000 [==============================] - 1s 104us/step - loss: 0.3418 - accuracy: 0.8611\n","Epoch 73/100\n","8000/8000 [==============================] - 1s 105us/step - loss: 0.3419 - accuracy: 0.8619\n","Epoch 74/100\n","8000/8000 [==============================] - 1s 103us/step - loss: 0.3415 - accuracy: 0.8605\n","Epoch 75/100\n","8000/8000 [==============================] - 1s 104us/step - loss: 0.3418 - accuracy: 0.8622\n","Epoch 76/100\n","8000/8000 [==============================] - 1s 107us/step - loss: 0.3417 - accuracy: 0.8605\n","Epoch 77/100\n","8000/8000 [==============================] - 1s 105us/step - loss: 0.3415 - accuracy: 0.8612\n","Epoch 78/100\n","8000/8000 [==============================] - 1s 105us/step - loss: 0.3414 - accuracy: 0.8614\n","Epoch 79/100\n","8000/8000 [==============================] - 1s 107us/step - loss: 0.3407 - accuracy: 0.8618\n","Epoch 80/100\n","8000/8000 [==============================] - 1s 105us/step - loss: 0.3414 - accuracy: 0.8629\n","Epoch 81/100\n","8000/8000 [==============================] - 1s 104us/step - loss: 0.3415 - accuracy: 0.8610\n","Epoch 82/100\n","8000/8000 [==============================] - 1s 116us/step - loss: 0.3415 - accuracy: 0.8618\n","Epoch 83/100\n","8000/8000 [==============================] - 1s 123us/step - loss: 0.3412 - accuracy: 0.8633\n","Epoch 84/100\n","8000/8000 [==============================] - 1s 106us/step - loss: 0.3414 - accuracy: 0.8610\n","Epoch 85/100\n","8000/8000 [==============================] - 1s 119us/step - loss: 0.3414 - accuracy: 0.8636\n","Epoch 86/100\n","8000/8000 [==============================] - 1s 117us/step - loss: 0.3414 - accuracy: 0.8612\n","Epoch 87/100\n","8000/8000 [==============================] - 1s 110us/step - loss: 0.3403 - accuracy: 0.8624\n","Epoch 88/100\n","8000/8000 [==============================] - 1s 104us/step - loss: 0.3410 - accuracy: 0.8606\n","Epoch 89/100\n","8000/8000 [==============================] - 1s 106us/step - loss: 0.3413 - accuracy: 0.8609\n","Epoch 90/100\n","8000/8000 [==============================] - 1s 116us/step - loss: 0.3403 - accuracy: 0.8634\n","Epoch 91/100\n","8000/8000 [==============================] - 1s 108us/step - loss: 0.3401 - accuracy: 0.8634\n","Epoch 92/100\n","8000/8000 [==============================] - 1s 120us/step - loss: 0.3407 - accuracy: 0.8637\n","Epoch 93/100\n","8000/8000 [==============================] - 1s 106us/step - loss: 0.3405 - accuracy: 0.8630\n","Epoch 94/100\n","8000/8000 [==============================] - 1s 121us/step - loss: 0.3416 - accuracy: 0.8614\n","Epoch 95/100\n","8000/8000 [==============================] - 1s 104us/step - loss: 0.3410 - accuracy: 0.8627\n","Epoch 96/100\n","8000/8000 [==============================] - 1s 111us/step - loss: 0.3402 - accuracy: 0.8629\n","Epoch 97/100\n","8000/8000 [==============================] - 1s 112us/step - loss: 0.3407 - accuracy: 0.8609\n","Epoch 98/100\n","8000/8000 [==============================] - 1s 104us/step - loss: 0.3399 - accuracy: 0.8616\n","Epoch 99/100\n","8000/8000 [==============================] - 1s 110us/step - loss: 0.3410 - accuracy: 0.8608\n","Epoch 100/100\n","8000/8000 [==============================] - 1s 116us/step - loss: 0.3393 - accuracy: 0.8624\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.callbacks.History at 0x7ff509e86cc0>"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"huOZnkQhLQcF","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593285585005,"user_tz":-360,"elapsed":1237,"user":{"displayName":"Sawradip Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjiknncyResq9DxB1krpJnhEFgTIz65ifrUq64R2hs=s64","userId":"07399611378604694216"}}},"source":["#predicting the Test Set results\n","\n","y_pred = classifier.predict(X_test)\n","y_pred = (y_pred >0.5)"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"v_c420VYLTEl","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593285753116,"user_tz":-360,"elapsed":1195,"user":{"displayName":"Sawradip Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjiknncyResq9DxB1krpJnhEFgTIz65ifrUq64R2hs=s64","userId":"07399611378604694216"}}},"source":["#Making the confusion matrix\n","from sklearn.metrics import confusion_matrix\n","cm = confusion_matrix( y_test , y_pred)"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"bRBCXi99OzQH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1593285763463,"user_tz":-360,"elapsed":1275,"user":{"displayName":"Sawradip Saha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjiknncyResq9DxB1krpJnhEFgTIz65ifrUq64R2hs=s64","userId":"07399611378604694216"}},"outputId":"dea1fcfd-7fcd-40d9-8f58-aeef61b587c4"},"source":["cm"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1491,  104],\n","       [ 178,  227]])"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"4RUwUTnsO1xE","colab_type":"code","colab":{}},"source":[" "],"execution_count":null,"outputs":[]}]}